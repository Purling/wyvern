/* A lexer for the untyped lambda calculus

example: (x => x) (y => y)

IDENTIFIER  [a-zA-Z][a-zA-Z0-9_]*
LPAREN      (   
RPAREN      )
WHITESPACE  [ \t\r\l]+
DARROW      =>

*/

require stdout

import wyvern.util.matching.regex

import lexBuilder

datatype TokenKind
    IDENTIFIER
    LPAREN
    RPAREN
    WHITESPACE
    DARROW
    
val builder = lexBuilder[TokenKind]()

// FIX: define these with a nice DSL

// FIX: either use a literal syntax for lists
// or be imperative with a literal syntax for pairs: lexTable.add({identPat, IDENTIFIER})

builder.addEntry(regex("[a-zA-Z][a-zA-Z0-9_]*"), IDENTIFIER())
builder.addEntry(regex("\\("), LPAREN())
builder.addEntry(regex("\\)"), RPAREN())
builder.addEntry(regex("[ \t\r\f]+"), WHITESPACE())
builder.addEntry(regex("=>"), DARROW())

val testLexer = builder.build()

// FIX: no parens for unit constructors    
val t : TokenKind = IDENTIFIER()


// FIX: don't need a _ for these!
def printKind(kind:TokenKind):Unit = match kind:
    _:IDENTIFIER => stdout.print("IDENTIFIER")
    _:LPAREN => stdout.print("LPAREN")
    _:RPAREN => stdout.print("RPAREN")
    _:WHITESPACE => stdout.print("WHITESPACE")
    _:DARROW => stdout.print("DARROW")

def printTokens(result:testLexer.ParseResult):Unit = match result:
    s:testLexer.Success => 
        s.tokens.do(t =>
            printKind(t.kind)
            stdout.print(": '" + t.value + "'")
            stdout.println()
        )
    e:testLexer.Error => stdout.print("Lex error: " + e.unmatchableText)

// test it
/*val m = identPat.findPrefixMatchOf("h3llo+5").get()
stdout.print(m.matched())
stdout.println()
stdout.print(m.after())
stdout.println()*/

val res:testLexer.ParseResult = testLexer.lex("(x => x) (y => y)")
printTokens(res)
match res:
    e:testLexer.Error => 0
    s:testLexer.Success => s.tokens.size()