module def wyvernLexer(js:Dyn, regexUtils:Dyn)

import metadata lexing
import wyvern.collections.llist
import wyvern.runtime
import lexUtil

type List = llist.LinkedList

/************** Tokens ***************/

type Token
    val "type":String
    val value:String
    val line:Int
    val col:Int

def Token(t:String, value:String, line:Int, col:Int):Token = new
    val "type":String = t
    val value:String = value
    val line:Int = line
    val col:Int = col


/************** First Level Lexer ***************/

// note: this lexer will never actually see a logline (\n, \r, or \r\n).  But we generate such tokens later on at line breaks

val lowLevelLexer : lexing.Lexer = ~
        WS:         /[ \t]+/,
        logline:    {match: /\\r\\n|\\r|\\n/, lineBreaks: true},
        identifier: {match: /[a-zA-Z][a-zA-Z0-9_]*/, type: moo.keywords({ 
            val      : 'val', 
            def      : 'def', 
            type     : 'type', 
            new_     : 'new',
            subtype  : 'subtype',
            extends_ : 'extends'
        })},
        lparen:     '(',
        rparen:     ')',
        lbrack:     '[',
        rbrack:     ']',
        lcurl:      '{',
        rcurl:      '}',
        darrow:     '=>',
        arrow:      '->',
        colon:      ':',
        eq:         '=',
        leq:        '<=',
        geq:        '>=',
        dot:        '.',
        comma:      ',',
        linecont:   '\\',
        plus:       '+',
        minus:      '-',
        times:      '*',
        divide:     '/',
        mod:        '%',
        block:      '#BLOCK#',
        integer:    /\d+/,

val startLexerState = lowLevelLexer.save()
        
def lowerLexOrdinaryLine(input:String):List[Dyn]
    var tokens : List[Dyn] = llist.Nil[Dyn]()
    lowLevelLexer.reset(input, startLexerState)
    var token : Dyn = lowLevelLexer.next()
    //js.log("called lowerLexOrdinaryLine")
    def loop():Unit
        if (!js.isUndefined(token))
            tokens = tokens.push(token)
            token = lowLevelLexer.next()
            loop()
    loop()
    val result = tokens.reverse()
    result

// converts the string into a token.  We assume the string does not include a newline.
// TODO: return token with correct line/column
def lexIndentedLine(input:String):Token = Token("indentedLine", input, -1, -1)

/************** Second Level Lexer ***************/
    
datatype LexerState
    Indent(level:String)
    LParen()
    RParen()
    LBrack()
    RBrack()
    Block(text:String)
    LineCont()
    OpenComment()
    DontCare()

def printToken(t:Dyn):Unit = js.log(t."type")

def printTokens(tokens:List[Dyn]):Unit
    tokens.do(x => printToken(x))

val NO_INDENT = "NONE"

def isStrictSubstring(s1:String,s2:String):Boolean
    if (s1.length() < s2.length())
        val s2part = s2.substring(0, s1.length())
        s1 == s2part
      else
        false

def allWhitespaceTokens(toks:List[Token]):Boolean = match toks:
    c:llist.Cons =>
        if (c.value."type" == "WS")
            allWhitespaceTokens(c.next)
          else
            false
    default => true

resource type SecondLevelLexer
    def lexLines(input:String):List[Dyn]

def makeSecondLevelLexer():SecondLevelLexer = new (self) =>
    var lexerState:List[LexerState] = llist.Nil[LexerState]()
        
    def getCurrentIndent() : String
        def findIndent(l:List[LexerState]):String = match l:
            n:llist.Nil => NO_INDENT
            c:llist.Cons => match c.value:
                i:Indent => i.level
                default  => findIndent(c.next)
        findIndent(self.lexerState)

    def setIndent(lineIndent:String):Unit
        match self.lexerState:
            c:llist.Cons =>
                self.lexerState = self.lexerState.drop(1).get()
                match c.value:
                    i:Indent =>
                        self.lexerState = self.lexerState.push(Indent(lineIndent))
                    default =>
                        self.setIndent(lineIndent)
                        self.lexerState = self.lexerState.push(c.value)
            default => unit

    // returns a new pending list with dedents prepended
    def addDedents(lineIndent:String, pending:List[Dyn], tokens:List[Token]):List[Dyn]
        match self.lexerState:
            c:llist.Cons =>
                self.lexerState = self.lexerState.drop(1).get()
                match c.value:
                    i:Indent => self.addDedents(lineIndent, pending.push(Token("dedent","", 0, 0)), tokens)
                    l:LParen => pending
                    l:LBrack => pending
            n:llist.Nil =>
                runtime.fail("didn't match indent/dedent")

    // passed input one line at a time, not including the terminating \n
    def lexLine(input:String):List[Dyn]
        var pending:List[Dyn] = llist.Nil[Dyn]() // in reverse order
        val topState = self.lexerState.nth(0).getOrElse(() => DontCare())
        // TODO: bug in codegen means have to let-bind topState
        match topState:
            b:Block =>
                var currentIndent1 : String = self.getCurrentIndent()
                if (currentIndent1 == "NONE")
                    currentIndent1 = ""
                val lineIndent = lexUtil.getIndent(input)
                if (isStrictSubstring(currentIndent1,lineIndent) || lexUtil.allWhitespace(input))
                    // extending the block
                    val token = lexIndentedLine(input)
                    self.lexerState = self.lexerState.drop(1).get()
                    self.lexerState = self.lexerState.push(Block(b.text + token.value + "\n"))
                    pending // empty
                  else
                    // ending the block
                    // TODO: get location right
                    pending = pending.push(Token("block", b.text, -1, -1))
                    self.lexerState = self.lexerState.drop(1).get()
                    self.lexOrdinaryLine(pending, input)
            default =>
                self.lexOrdinaryLine(pending, input)

    def lexOrdinaryLine(pending_:List[Dyn], input:String):List[Dyn]
        val tokens = lowerLexOrdinaryLine(input)
        var pending:List[Dyn] = pending_ // in reverse order
        val topState = self.lexerState.nth(0).getOrElse(() => DontCare())
        if (lexUtil.allWhitespace(input))
            // if self.lexerState.top()==LINECONTINUATION && tokens.last != LINECONTINUATION
            match topState:
                l:LineCont =>
                    if (!(tokens.nth(tokens.size()-1).map[String](x:Token => x."type").getOrElse(() => "") == "linecont"))
                        self.lexerState = self.lexerState.drop(1).get()
                default    =>
                    unit
            pending.reverse().append(tokens)
          else
            match topState:
                l:LineCont =>
                    self.lexerState = self.lexerState.drop(1).get()
                    self.handleLine(pending, tokens)
                l:LParen => self.handleLine(pending, tokens)
                l:LBrack => self.handleLine(pending, tokens)
                default =>
                    var currentIndent1 : String = self.getCurrentIndent()
                    val lineIndent = lexUtil.getIndent(input)
                    if (currentIndent1 == NO_INDENT)
                        self.setIndent(lineIndent)
                        currentIndent1 = ""
                    if (currentIndent1 == lineIndent)
                        // new line at same indent level
                        // TODO: fix line/column here
                        pending = pending.push(Token("logline","\n",0,0))
                        self.handleLine(pending, tokens)
                      elif (isStrictSubstring(lineIndent,currentIndent1))
                        // one or more dedents
                        self.addDedents(lineIndent, pending, tokens)
                      else
                        // lineIndent > currentIndent1
                        self.handleLine(pending, tokens)
                
    def handleLine(pending_:List[Dyn], tokens:List[Token]):List[Dyn]
        //inLine = true
        var toks:List[Dyn] = tokens
        printTokens(toks)
        var pending:List[Dyn] = pending_ // in reverse order
        
        def computeDedents(matchingType:String):Unit
            val top = self.lexerState.nth(0).get()
            self.lexerState = self.lexerState.drop(1).get()
            val errorString = "didn't match token " + matchingType
            match top:
                i:Indent =>
                    pending = pending.push(Token("dedent", "", 0, 0))
                    computeDedents(matchingType)
                l:LParen => runtime.assertion(errorString, matchingType == "lparen")
                l:LBrack => runtime.assertion(errorString, matchingType == "lbrack")
                default  => runtime.fail(errorString)
        
        def loop():Unit
          match toks:
            c:llist.Cons => 
                toks = c.next
                val t:Token = c.value
                val kind = t."type"
                if (kind == "lparen")
                    self.lexerState = self.lexerState.push(LParen())
                  elif (kind == "lbrack")
                    self.lexerState = self.lexerState.push(LBrack())
                  elif (kind == "rparen")
                    computeDedents("lparen")
                  elif (kind == "rbrack")
                    computeDedents("lbrack")
                  elif (kind == "colon")
                    if (allWhitespaceTokens(toks))
                        self.lexerState = self.lexerState.push(Block(""))
                  elif (kind == "eqarrow")
                    if (allWhitespaceTokens(toks))
                        self.lexerState = self.lexerState.push(Indent(NO_INDENT))
                  else
                    unit
                pending = pending.push(t)
                loop()
            n:llist.Nil => unit
        
        loop()
        // if ends with linecont, set the flag and don't add linecont
        match pending:
            c:llist.Cons =>
                val t : Token = c.value
                if (t."type" == "linecont")
                    pending = c.next
                    self.lexerState = self.lexerState.push(LineCont())

        // return pending (reversed)
        pending.reverse()


    // WITH CONTINUATION: lex a line and return whether it is a complete logical line or not (store internally if not, return if so)
            
    // lex multiple lines to return a combined list (uses module-global variable, same as above)
    def lexLines(input:String):List[Dyn]
        val lineMatch = regexUtils.doMatch(input, "[^\\r\\n]*")
        if (lineMatch.found)
            js.log("reading line \"" + lineMatch.matched + "\"")
            val firstTokens = self.lexLine(lineMatch.matched)
            printTokens(firstTokens)
            if (lineMatch.after == "")
                def getBlocks():List[Dyn]
                    val topState = self.lexerState.nth(0).getOrElse(() => DontCare())
                    var pending:List[Dyn] = llist.Nil[Dyn]() // in reverse order
                    match topState:
                        b:Block => 
                            val newblock = Token("block",b.text,-1,-1)
                            pending = pending.push(newblock)
                            self.lexerState = self.lexerState.drop(1).get()
                            pending.append(getBlocks())
                        default => llist.Nil[Dyn]()
                firstTokens.append(getBlocks())
              else
                val newlineMatch = regexUtils.doMatch(lineMatch.after, "\\r\\n|\\r|\\n")
                val restTokens = self.lexLines(newlineMatch.after)
                firstTokens.append(restTokens)
          else
              llist.Nil[Dyn]()
        //js.log(newlineMatch.found)
        //js.log(newlineMatch.matched)
        //js.log(newlineMatch.after)

resource type IncrementalLexer
    def addLine(input:String):option.Option[lexing.Lexer]

    /*
// TODO: revise to work with lineCont
def incrementalLexer():IncrementalLexer
    // TODO: make all the state above local
    new
        var tokens : List[Dyn] = llist.Nil[Dyn]()
        def addLine(input:String):option.Option[lexing.Lexer]
            this.tokens = this.tokens.append(lexLine(input))
            if (lineCont)
                option.None[lexing.Lexer]()
              else
                option.Some[lexing.Lexer](initLexer(this.tokens))
*/

def makeLexer():lexing.Lexer
    initLexer(llist.Nil[Dyn]())
    
def initLexer(toks : List[Dyn]):lexing.Lexer
    var tokens : List[Dyn] = toks
    new
        def next():Dyn = match tokens:
            c:llist.Cons =>
                           tokens = c.next
                           val token:Dyn = c.value
                           //js.log("lexer returning " + token.value)
                           c.value
            n:llist.Nil => js.getUndefined()
        def save():Dyn = js.log("called save\n")
        def reset(chunk:String, info:Dyn):Unit
            js.log("called reset\n")
            val secondLevelLexer = makeSecondLevelLexer()
            tokens = secondLevelLexer.lexLines(chunk).filter((t:Dyn) => !js.equalsJS("WS", t."type"))
            //tokens.do((t:Dyn) => printToken(t))
        def formatError(token:Dyn):String
            js.log("called formatError")
            js.log(token)
            "this is an error"
        def has(name:String):Boolean = lowLevelLexer.has(name)
